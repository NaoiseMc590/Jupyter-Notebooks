{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Crawler\n",
    "\n",
    "**Task:**\n",
    "\n",
    "- Customize the ArticleFetcher to extract information from all pages\n",
    "\n",
    "Here is the URL again: http://python.beispiel.programmierenlernen.io/index.php\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- First look at how you can click on the button \"Zur nÃ¤chsten Seite\".\n",
    "- How do you access the \"href\" attribute of this button from Python?\n",
    "- (Optional): Try to get only the information of the first 2 pages first if necessary. Based on this, can you generalize the program so that it reads all pages?\n",
    "- You can decide whether there is a \"Zur nÃ¤chsten Seite\" button or not. If this button no longer exists, you have reached the last page. Which loop type is suitable here if you do not want to stop the loop until the button no longer exists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://python.beispiel.programmierenlernen.io/index.php\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=2\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=2\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=3\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=3\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=4\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=4\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=5\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=5\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=6\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=6\n",
      "http://python.beispiel.programmierenlernen.io/index.php\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=2\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=2\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=3\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=3\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=4\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=4\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=5\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=5\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=6\n",
      "http://python.beispiel.programmierenlernen.io/index.php?page=6\n",
      "ğŸ˜© : Polarised modular conglomeration\n",
      "ğŸ˜ : Cross-group contextually-based middleware\n",
      "ğŸ˜Œ : De-engineered encompassing structure\n",
      "ğŸ˜š : Fully-configurable multi-tasking interface\n",
      "ğŸ˜  : Versatile eco-centric core\n",
      "ğŸ˜® : Optional maximized utilisation\n",
      "ğŸ˜¢ : Open-architected secondary product\n",
      "ğŸ˜  : Realigned zerotolerance function\n",
      "ğŸ˜† : Quality-focused user-facing help-desk\n",
      "ğŸ˜¤ : Proactive user-facing opensystem\n",
      "ğŸ˜Ÿ : Decentralized holistic moderator\n",
      "ğŸ˜Œ : Mandatory tangible application\n",
      "ğŸ˜“ : Digitized dedicated budgetarymanagement\n",
      "ğŸ˜ : Organized well-modulated concept\n",
      "ğŸ˜¢ : Balanced optimal openarchitecture\n",
      "ğŸ˜ : Universal explicit throughput\n",
      "ğŸ˜³ : Polarised mobile algorithm\n",
      "ğŸ˜š : Mandatory homogeneous infrastructure\n",
      "ğŸ˜² : Business-focused interactive implementation\n",
      "ğŸ˜¯ : Polarised exuding archive\n",
      "ğŸ˜µ : Extended homogeneous firmware\n",
      "ğŸ˜‹ : Secured transitional capability\n",
      "ğŸ˜´ : Expanded clear-thinking forecast\n",
      "ğŸ˜‡ : Grass-roots assymetric interface\n",
      "ğŸ˜ˆ : Inverse static service-desk\n",
      "ğŸ˜ : Optional object-oriented toolset\n",
      "ğŸ˜§ : Optional stable service-desk\n",
      "ğŸ˜ˆ : Virtual background systemengine\n",
      "ğŸ˜¶ : Balanced human-resource extranet\n",
      "ğŸ˜„ : Expanded bi-directional encryption\n",
      "ğŸ˜© : Sharable client-driven groupware\n",
      "ğŸ˜¬ : Monitored even-keeled initiative\n",
      "ğŸ˜ˆ : Inverse maximized benchmark\n",
      "ğŸ˜Š : Front-line full-range help-desk\n",
      "ğŸ˜… : Integrated impactful matrices\n",
      "ğŸ˜„ : Cross-platform composite data-warehouse\n",
      "ğŸ˜´ : Grass-roots systemic support\n",
      "ğŸ˜‚ : Secured 3rdgeneration intranet\n",
      "ğŸ˜• : Persistent composite firmware\n",
      "ğŸ˜Š : Upgradable multimedia benchmark\n",
      "ğŸ˜¦ : Organized fresh-thinking utilisation\n"
     ]
    }
   ],
   "source": [
    "class CrawledArticle():\n",
    "    def __init__(self, title, emoji, content, image):\n",
    "        self.title = title\n",
    "        self.emoji = emoji\n",
    "        self.content = content\n",
    "        self.image = image\n",
    "        \n",
    "class ArticleFetcher():\n",
    "    def fetch(self):\n",
    "        url = \"http://python.beispiel.programmierenlernen.io/index.php\"\n",
    "        \n",
    "        articles = []\n",
    "        \n",
    "        while url != '':\n",
    "            print(url)\n",
    "            time.sleep(1)\n",
    "            r = requests.get(url)\n",
    "            doc = BeautifulSoup(r.text, \"html.parser\")\n",
    "        \n",
    "            \n",
    "            for card in doc.select(\".card\"):\n",
    "                emoji = card.select_one(\".emoji\").text\n",
    "                content = card.select_one(\".card-text\").text\n",
    "                title = card.select(\".card-title span\")[1].text\n",
    "                image = urljoin(url, card.select_one(\"img\").attrs[\"src\"])\n",
    "\n",
    "                crawled = CrawledArticle(title, emoji, content, image)\n",
    "                articles.append(crawled)\n",
    "                \n",
    "            \n",
    "            next_btn = doc.select_one('.navigation .btn')\n",
    "            if next_btn:\n",
    "                  next_href = doc.select_one('.navigation .btn').attrs['href']\n",
    "                  next_href = urljoin(url, next_href)\n",
    "                  url = next_href\n",
    "                  print(next_href)\n",
    "            else:\n",
    "                url = ''\n",
    "            \n",
    "            \n",
    "        \n",
    "        return articles\n",
    "    \n",
    "fetcher = ArticleFetcher()\n",
    "fetcher.fetch()  \n",
    "for article in fetcher.fetch():\n",
    "    print(article.emoji + ' : ' + article.title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
